#ifndef JOB_H
#define JOB_H
#include <string>
#include <unordered_map>
#include <queue>

// //Information needed to a specify a Job
// struct Job {
//     int                                        _id{};
//     std::string                                 id{};
//     std::string                                 status{};
//     int                                         error_code{};
//     long long                                   flops{};
//     std::unordered_map<std::string, size_t>     input_files{};
//     std::unordered_map<std::string, size_t>     output_files{};
//     size_t                                      input_storage{};
//     size_t                                      output_storage{};
//     int                                         priority{};
//     int                                         cores{};
//     std::string                                 mount{};
//     std::string                                 disk{};
//     std::string                                 comp_host{};
//     std::string                                 comp_site{};
//     size_t                                      IO_size_performed{};
//     double                                      IO_time_taken{};
//     double                                      EXEC_time_taken{};
//     int                                         files_read{};
//     int                                         files_written{};
//     double                                      memory_usage{};
//     bool operator<(const Job& other) const {if(priority == other.priority){return _id > other._id;} return priority < other.priority;}
// };

//Information needed to a specify a Job
struct Job {
    long long              jobid{}; // this equivalent to PANDAID in historical hjo
    std::string            creation_time{}; //generated by Oracle's SYSDATE function when the job is inserted to jobsDefined4
    std::string            job_status{}; // status of the job
    std::string            job_name{}; // the job name defined in prodDB
    double                 cpu_consumption_time{}; //actual execution time of the job
    std::string            comp_site{}; //site name where the job runs
    std::string            destination_dataset_name{}; //name of destination dataset for the job; is used to register the outputs of an associated set of jobs as belonging to one block to be saved at an archival destination
    std::string            destination_SE{}; // destination storage element of job output files
    std::string            source_site{}; // source site (usually CE) for file transfer
    std::string            transfer_type{}; //type of file transfer
    int                    core_count{}; //the number of CPU cores
    int                    no_of_inp_files{}; // the number of input files
    double                 inp_file_bytes{}; // the total size of input files
    int                    no_of_out_files{}; // the number of output files
    double                 out_file_bytes{}; // the total size of output files
    std::string            pilot_error_code{}; // pilot error code
    std::string            exe_error_code{}; // executor error code
    std::string            ddm_error_code{}; // DDM error code
    std::string            dispatcher_error_code{}; // jobDispatcher error code
    std::string            taskbuffer_error_code{}; // taskBuffer error code
    std::string            status{}; // taskBuffer error code
   
    // flops field is calculated with an approximation in PANDA_DISPATCHER::allocateResourcesToJobs
    long long                 flops{};
    // below fields will be assigned by dispatcher
    int                                         cores{}; // core_count
    std::string                                 disk{};
    std::string                                 comp_host{}; // cpu
    // TODO fields moved for compatibility with base code, either merge or remove later  
    size_t                                      IO_size_performed{}; // no_of_inp_files*inp_file_bytes +
    double                                      IO_time_taken{};
    double                                      EXEC_time_taken{};
    int                                         files_read{}; //inp_file_bytes
    int                                         files_written{};//out_file_bytes
    double                                      memory_usage{};
    std::string                                 mount{};
    std::string                                 id{};
    std::unordered_map<std::string, size_t>     input_files{};//no_of_inp_files
    std::unordered_map<std::string, size_t>     output_files{};//no_of_out_files
  
  
  };

using JobQueue = std::priority_queue<Job*>;


#endif //JOB_H
